{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152713,"status":"ok","timestamp":1673901326784,"user":{"displayName":"Alexandros Gkillas","userId":"06090391217186072891"},"user_tz":-120},"id":"KSarUKjTzfVN","outputId":"d3dd7ea3-2462-48b3-9f91-e969ec4cdc00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ttictoc\n","  Downloading ttictoc-0.5.6-py3-none-any.whl (5.7 kB)\n","Installing collected packages: ttictoc\n","Successfully installed ttictoc-0.5.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imagesc\n","  Downloading imagesc-0.3.0-py3-none-any.whl (15 kB)\n","Collecting ismember\n","  Downloading ismember-1.0.2-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imagesc) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from imagesc) (21.3)\n","Collecting d3heatmap\n","  Downloading d3heatmap-0.2.3-py3-none-any.whl (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 KB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imagesc) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from imagesc) (1.3.5)\n","Collecting clusteval\n","  Downloading clusteval-2.1.4-py3-none-any.whl (32 kB)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imagesc) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imagesc) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imagesc) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imagesc) (1.4.4)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->imagesc) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->imagesc) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from clusteval->d3heatmap->imagesc) (4.64.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from clusteval->d3heatmap->imagesc) (0.11.2)\n","Collecting pypickle\n","  Downloading pypickle-1.1.0-py3-none-any.whl (5.1 kB)\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from clusteval->d3heatmap->imagesc) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->clusteval->d3heatmap->imagesc) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->clusteval->d3heatmap->imagesc) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->clusteval->d3heatmap->imagesc) (1.2.0)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=a6f983a25b587ba1606f060c5bd6ed0e7c2a835163c2431379f588478be76194\n","  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n","Successfully built wget\n","Installing collected packages: wget, pypickle, ismember, clusteval, d3heatmap, imagesc\n","Successfully installed clusteval-2.1.4 d3heatmap-0.2.3 imagesc-0.3.0 ismember-1.0.2 pypickle-1.1.0 wget-3.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mat73\n","  Downloading mat73-0.59-py3-none-any.whl (19 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mat73) (1.21.6)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from mat73) (3.1.0)\n","Installing collected packages: mat73\n","Successfully installed mat73-0.59\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.18.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.6)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.10.10)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","Successfully installed scikit-image-0.19.3\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a8dbf931878f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructural_similarity\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mpy_file_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/DEEP_UNROLLING_phd/MY_PROPOSED_MODELS_PAPER\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_file_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#@title Dependencies\n"," # Equilibrium HQS\n","!pip install ttictoc\n","from ttictoc import tic,toc\n","import torch\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import torch.autograd as autograd\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from scipy.io import loadmat\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction import image\n","from pathlib import Path\n","from PIL import Image\n","import random, math\n","import numpy as np\n","!pip install imagesc\n","import imagesc as imagesc\n","import scipy\n","from torch.autograd import Variable\n","from torch.nn import Linear, ReLU, LeakyReLU, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n","import glob\n","!pip install mat73\n","import mat73\n","import random\n","import sys\n","import os\n","!pip install -U scikit-image\n","import skimage\n","from functools import partial\n","import cv2\n","from sklearn.linear_model import OrthogonalMatchingPursuit\n","from math import log10, sqrt\n","from google.colab import drive\n","from sklearn import preprocessing\n","from skimage.metrics import structural_similarity as ssim\n","drive.mount(\"/content/drive/\", force_remount=True)\n","py_file_location = \"/content/drive/My Drive/Colab Notebooks/DEEP_UNROLLING_phd/MY_PROPOSED_MODELS_PAPER\"\n","sys.path.append(os.path.abspath(py_file_location))\n","\n","\n","# Set the GPu as default\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#------------------------------------------------------------------------------#\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs6ure7xFwCp"},"outputs":[],"source":["#@title Read Data and Testing Functions\n","def read_test_hyperspectral_images(image_path, indx):\n","    os.chdir(image_path)\n","    mat_files = glob.glob('*.mat')\n","    fname = mat_files[indx]\n","    print(fname)\n","    matData = mat73.loadmat(fname)\n","    spectra = matData['rad']\n","    spectra = spectra[0:1000, 0:1000,:]\n","    #spectra = min_max_normalized(spectra)\n","    spectra = (spectra-np.amin(spectra))/(np.amax(spectra)-np.amin(spectra))\n","    return spectra\n","\n","def myPSNR(original, compressed):\n","    mse = np.mean((original - compressed) ** 2)\n","    max_pixel = np.amax(original)\n","    psnr = 20 * log10(max_pixel / sqrt(mse))\n","    return psnr\n","\n","def add_gaussian_noise_matrix_form(Hd, sigma):\n","    [N,M,B] = Hd.shape\n","    noise = sigma/255*np.random.randn(N, M, B);\n","    Hd_noisy = Hd + noise\n","    return Hd_noisy\n","\n","\n","def add_gaussian_noise_matrix_form_colored_stripe(Hd, sigma):\n","  [N,M,B] = Hd.shape\n","  Hd_noisy = np.zeros(Hd.shape)\n","  for i in range(Hd.shape[2]):\n","\n","        sigma = [5, 10, 10, 30, 40, 60]\n","        noise = random.choice(sigma)/255*np.random.randn(N, M);\n","        Hd_noisy[:,:,i] = Hd[:,:,i] + noise\n","\n","  min_amount = 0.05;\n","  max_amount = 0.15;\n","  band = np.random.permutation(B);\n","  band = band[0:10];\n","  stripnum = np.random.randint(math.ceil(min_amount * N), math.ceil(max_amount * N), band.shape[0]);\n","  for i in range(band.shape[0]):\n","    loc = np.random.permutation(N);\n","    a = stripnum[i]\n","    loc = loc[1:a];\n","    stripe = np.random.rand(1, loc.shape[0])*0.5-0.25;\n","    Hd_noisy[:,loc,band[i]] = Hd_noisy[:,loc,band[i]] -stripe\n","\n","\n","  return Hd_noisy\n","\n","def add_gaussian_noise_matrix_form_colored_deadline(Hd, sigma):\n","  [N,M,B] = Hd.shape\n","  Hd_noisy = np.zeros(Hd.shape)\n","  for i in range(Hd.shape[2]):\n","\n","        sigma = [5, 10, 10, 30, 40, 60]\n","        noise = random.choice(sigma)/255*np.random.randn(N, M);\n","        Hd_noisy[:,:,i] = Hd[:,:,i] + noise\n","\n","  min_amount = 0.05;\n","  max_amount = 0.15;\n","  band = np.random.permutation(B);\n","  band = band[0:10];\n","  stripnum = np.random.randint(math.ceil(min_amount * N), math.ceil(max_amount * N), band.shape[0]);\n","  for i in range(band.shape[0]):\n","    loc = np.random.permutation(N);\n","    a = stripnum[i]\n","    loc = loc[1:a];\n","    stripe = np.random.rand(1, loc.shape[0])*0.5-0.25;\n","    # Hd_noisy[:,loc,band[i]] = Hd_noisy[:,loc,band[i]] -stripe\n","    Hd_noisy[:,loc,band[i]] = 0\n","\n","  return Hd_noisy\n","\n","def construct_the_training_dataset(num_of_patches, patch_size, sparsity_level, D, image_path, noIm_start, noIm_end, sigma, gaus_sigma, rcond):\n","    # In this function random patches are extracted from a hyperspectral image\n","    # and its noisy version and the sparse coding matrices are estimated\n","    Ds_sup = []\n","    Noisy_data = []\n","    Clean_data = []\n","    cnt = 1\n","    for indx in range(noIm_start, noIm_end):\n","       print(indx)\n","       # Read a hyperspectral Image\n","       X = read_test_hyperspectral_images(image_path, indx)\n","       X_noisy = add_gaussian_noise_matrix_form(X, sigma)\n","      #  X_noisy = add_gaussian_noise_matrix_form_colored_stripe(X, sigma)\n","      #  X_noisy = add_gaussian_noise_matrix_form_colored_deadline(X, sigma)\n","       cnt, support_patch, data_patch, clean_patch = extract_from_random_patches_SCM(X, X_noisy,\n","                                                  num_of_patches, patch_size, sparsity_level, D, cnt, rcond)\n","       if indx == noIm_start:\n","         Ds_sup = support_patch\n","         Noisy_data = data_patch\n","         Clean_data = clean_patch\n","       else:\n","         Ds_sup = np.concatenate((Ds_sup, support_patch))\n","         Noisy_data = np.concatenate((Noisy_data, data_patch))\n","         Clean_data = np.concatenate((Clean_data, clean_patch))\n","       del X, X_noisy\n","    return  Ds_sup, Noisy_data, Clean_data\n","\n","def extract_from_random_patches_SCM(X, X_noisy, num_of_patches, patch_size, sparsity_level, D, cnt, rcondition):\n","    # In this function random patches are extracted from a hyperspectral image\n","    # and its noisy version and the sparse coding matrices are estimate\n","    image_size = X.shape\n","    rI = random.sample(range(0, image_size[1]//patch_size-1), num_of_patches)\n","    rJ = random.sample(range(0, image_size[1]//patch_size-1), num_of_patches)\n","    #G2d_list = []\n","    #G2d_noisy_list = []\n","    dictionary_list = []\n","    data_list = []\n","    data_clean = []\n","\n","    for xx in range(num_of_patches):\n","        for yy in range(num_of_patches):\n","            i = rI[xx]\n","            j = rJ[yy]\n","            x = X[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size, :]\n","            x = (np.reshape(x, (patch_size*patch_size, image_size[2]))).T\n","            x_noisy = X_noisy[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size, :]\n","            x_noisy = (np.reshape(x_noisy, (patch_size*patch_size, image_size[2]))).T\n","            #Normlaize the data\n","            #norm_x_noisy = (np.sum(x_noisy**2, axis=0))**0.5;\n","            #x_noisy = np.divide(x_noisy, norm_x_noisy)\n","            #x = np.divide(x, norm_x_noisy)\n","            #Find the support set based on OMP algorithm and the centroid signal\n","            x_noisy_mean = np.mean(x_noisy, axis=1)\n","            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=sparsity_level, fit_intercept=False, normalize=False)\n","            omp.fit(D, x_noisy_mean)\n","            coef = omp.coef_\n","            sup, = coef.nonzero()\n","            #g = np.dot(np.linalg.pinv(D[:,sup], rcond=rcondition, hermitian=False),x)\n","            #g_noisy = np.dot(np.linalg.pinv(D[:,sup], rcond=rcondition, hermitian=False),x_noisy)\n","            #g_noisy= np.ones((sparsity_level,patch_size*patch_size))\n","            #g = np.reshape(g, (sparsity_level, patch_size, patch_size))\n","            #g_noisy = np.reshape(g_noisy, (sparsity_level, patch_size, patch_size))\n","            #G2d_list.append(g)\n","            #G2d_noisy_list.append(g_noisy)\n","            dictionary_list.append(D[:,sup])\n","            data_list.append(x_noisy)\n","            data_clean.append(x)\n","            cnt = cnt + 1\n","    return   cnt, dictionary_list, data_list, data_clean\n","\n","def reconstruct_hyperspectral_image(X, X_noisy, patch_size, sparsity_level, D, my_sc_model, rcodition, device, batch_size):\n","    # In this function random patches are extracted from an hyperspectral image\n","    # and its noisy version and the sparse coding matrices are estimated\n","    image_size = X.shape\n","    num_of_patch_i = image_size[0]//patch_size\n","    num_of_patch_j = image_size[1]//patch_size\n","    hd=np.zeros((image_size[0], image_size[1], image_size[2]))\n","    Data = []\n","    Dictionary = []\n","    Norm = []\n","    for i in range(num_of_patch_i):\n","        for j in range(num_of_patch_j):\n","            x_noisy = X_noisy[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size, :]\n","            x_noisy = (np.reshape(x_noisy, (patch_size*patch_size, image_size[2]))).T\n","            #Normlaize the data\n","            #norm_x_noisy = (np.sum(x_noisy**2, axis=0))**0.5;\n","            #Find the support set based on OMP algorithm and the centroid signal\n","            x_noisy_mean = np.mean(x_noisy, axis=1)\n","            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=sparsity_level, fit_intercept=False, normalize=False)\n","            omp.fit(D, x_noisy_mean)\n","            coef = omp.coef_\n","            sup, = coef.nonzero()\n","            # Forward model\n","            Ds = D[:,sup]\n","            data = x_noisy\n","            Dictionary.append(Ds)\n","            Data.append(data)\n","            #Norm.append(norm_x_noisy)\n","    del data\n","    Data = np.array(Data)\n","    Dictionary = np.array(Dictionary)\n","    #Norm = np.array(Norm)\n","\n","    dataloader_Dictionary = DataLoader(torch.from_numpy(Dictionary), batch_size, shuffle=False)\n","    dataloader_Data = DataLoader(torch.from_numpy(Data), batch_size, shuffle=False)\n","    #dataloader_Norm = DataLoader(torch.tensor(Norm), batch_size, shuffle=False)\n","    del Data, Dictionary\n","    Rec_Im = []\n","    cc = 0\n","    my_sc_model.eval()\n","    for data, Ds in zip(dataloader_Data, dataloader_Dictionary):\n","        batch_size = len(data)\n","        #norm = norm.numpy()\n","        with torch.no_grad():\n","          data = torch.autograd.Variable((data.float()).to(device))\n","          Ds = torch.autograd.Variable((Ds.float()).to(device))\n","\n","\n","        G = my_sc_model(data , Ds, len(data) , device)\n","        #norm = np.reshape(norm, (batch_size, 1, patch_size*patch_size))\n","        im = G.cpu().detach().numpy()\n","        del G\n","        im = np.reshape(im, (batch_size, data.shape[1], patch_size*patch_size))\n","        if cc == 0:\n","           Rec_Im = im\n","        else:\n","           Rec_Im = np.append(Rec_Im, im, axis=0)\n","        cc = cc + 1\n","        del data, Ds\n","    cnt = 0\n","    for i in range(num_of_patch_i):\n","       for j in range(num_of_patch_j):\n","          hd[i*patch_size:(i+1)*patch_size,j*patch_size:(j+1)*patch_size,:]= np.reshape((Rec_Im[cnt,:,:]).T, (patch_size, patch_size, 31))\n","          cnt = cnt + 1\n","    del Rec_Im, dataloader_Dictionary, dataloader_Data\n","    return hd\n","\n","\n","#Metrics\n","\n","def ssim(img1, img2):\n","    C1 = (0.01 * 255)**2\n","    C2 = (0.03 * 255)**2\n","\n","    img1 = img1.astype(np.float64)\n","    img2 = img2.astype(np.float64)\n","    kernel = cv2.getGaussianKernel(11, 1.5)\n","    window = np.outer(kernel, kernel.transpose())\n","\n","    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n","    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n","    mu1_sq = mu1**2\n","    mu2_sq = mu2**2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n","    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n","    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n","                                                            (sigma1_sq + sigma2_sq + C2))\n","    return ssim_map.mean()\n","\n","\n","def calculate_ssim(img1, img2):\n","    '''calculate SSIM\n","    the same outputs as MATLAB's\n","    img1, img2: [0, 255]\n","    '''\n","    if not img1.shape == img2.shape:\n","        raise ValueError('Input images must have the same dimensions.')\n","    if img1.ndim == 2:\n","        return ssim(img1, img2)\n","    elif img1.ndim == 3:\n","        if img1.shape[2] == 3:\n","            ssims = []\n","            for i in range(3):\n","                ssims.append(ssim(img1, img2))\n","            return np.array(ssims).mean()\n","        elif img1.shape[2] == 1:\n","            return ssim(np.squeeze(img1), np.squeeze(img2))\n","    else:\n","        raise ValueError('Wrong input image dimensions.')\n","\n","class Bandwise(object):\n","    def __init__(self, index_fn):\n","        self.index_fn = index_fn\n","\n","    def __call__(self, X, Y):\n","        C = X.shape[2]\n","        bwindex = []\n","        for ch in range(C):\n","            x = torch.squeeze(X[:,:,ch]).cpu().numpy()\n","            y = torch.squeeze(Y[:,:,ch]).cpu().numpy()\n","            index = self.index_fn(x, y)\n","            bwindex.append(index)\n","        return bwindex\n","\n","cal_bwssim = Bandwise(partial(ssim))\n","cal_bwpsnr = Bandwise(partial(skimage.metrics.peak_signal_noise_ratio, data_range=255))\n","\n","\n","def cal_sam(X, Y, eps=1e-8):\n","    X = X.cpu().numpy()\n","    Y = Y.cpu().numpy()\n","    tmp = (np.sum(X*Y, axis=2) + eps) / (np.sqrt(np.sum(X**2, axis=2)) + eps) / (np.sqrt(np.sum(Y**2, axis=2)) + eps)\n","    return np.mean(np.real(np.arccos(tmp)))\n","\n","\n","def MSIQA(X, Y):\n","    psnr = np.mean(cal_bwpsnr(X, Y))\n","    ssim = np.mean(cal_bwssim(X, Y))\n","    sam = cal_sam(X, Y)\n","    return psnr, ssim, sam"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"KyCRx6JYFgl5"},"outputs":[],"source":["#@title Deep Equilibrium Model\n","def anderson(f, x0, m=5, lam=1e-4, max_iter=50, tol=1e-2, beta = 1.0):\n","    \"\"\" Anderson acceleration for fixed point iteration. \"\"\"\n","\n","    #x0:Z_initial denotes the initial point to start\n","    bsz, d, H, W = x0.shape\n","    X = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n","    F = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n","    X[:,0], F[:,0] = x0.view(bsz, -1), f(x0).view(bsz, -1)\n","    X[:,1], F[:,1] = F[:,0], f(F[:,0].view_as(x0)).view(bsz, -1)\n","\n","    H = torch.zeros(bsz, m+1, m+1, dtype=x0.dtype, device=x0.device)\n","    H[:,0,1:] = H[:,1:,0] = 1\n","    y = torch.zeros(bsz, m+1, 1, dtype=x0.dtype, device=x0.device)\n","    y[:,0] = 1\n","\n","    res = []\n","    for k in range(2, 10):\n","        n = min(k, m)\n","        G = F[:,:n]-X[:,:n]\n","        H[:,1:n+1,1:n+1] = torch.bmm(G,G.transpose(1,2)) + lam*torch.eye(n, dtype=x0.dtype, device=x0.device)[None]\n","        alpha = torch.linalg.solve(H[:,:n+1,:n+1], y[:,:n+1])[:, 1:n+1, 0]   # (bsz x n)\n","\n","\n","        X[:,k%m] = beta * (alpha[:,None] @ F[:,:n])[:,0] + (1-beta)*(alpha[:,None] @ X[:,:n])[:,0]\n","        F[:,k%m] = f(X[:,k%m].view_as(x0)).view(bsz, -1)\n","        res.append((F[:,k%m] - X[:,k%m]).norm().item()/(1e-5 + F[:,k%m].norm().item()))\n","        if (res[-1] < tol):\n","            break\n","    #print(res[-1])\n","    return X[:,k%m].view_as(x0), res\n","\n","\n","class HQS_Module(nn.Module):\n","    def __init__(self, sparsity, patch_size, init_value, DnCnn):\n","        super().__init__()\n","\n","        self.DnCnn = DnCnn\n","        self.alpha = nn.Parameter(torch.tensor(init_value), requires_grad=True)\n","        self.sparsity = sparsity\n","        self.patch_size = patch_size\n","\n","    # Defining the forward pass\n","    def forward(self, z, data, dictionary, batch_size, device):\n","         z = z.to(device)\n","         z=torch.reshape(z,(batch_size, dictionary.shape[1], patch_size*patch_size))\n","\n","         ii=torch.eye(dictionary.shape[2])\n","         I=(ii.unsqueeze(0).repeat(batch_size, 1, 1)).to(device)\n","\n","         DT = torch.transpose(dictionary,1,2)\n","         G = torch.matmul(DT, dictionary)\n","         DtD = torch.inverse(G + G)\n","         A = torch.matmul(DT, data)\n","         A = self.alpha*A\n","         x = torch.matmul(DtD, (A + torch.matmul(DT, z)))\n","         z = (torch.matmul(dictionary, x)).to(device)\n","         z = torch.reshape(z, (batch_size, dictionary.shape[1], patch_size, patch_size))\n","         z = self.DnCnn(z)\n","\n","         #Output\n","         #z=torch.reshape(z, (batch_size, sparsity_level, patch_size*patch_size))\n","         return z\n","\n","class DEQFixedPoint(nn.Module):\n","    def __init__(self, f, sparsity, patch_size, device, solver, **kwargs):\n","        super().__init__()\n","        self.f = f\n","        self.solver = solver\n","        self.kwargs = kwargs\n","        self.sparsity = sparsity\n","        self.patch_size = patch_size\n","    def forward(self, data, dictionary, batch_size, device):\n","        # compute forward pass and re-engage autograd tape\n","        with torch.no_grad():\n","            z, self.forward_res = self.solver(lambda z : self.f(z, data, dictionary, batch_size, device), torch.ones(batch_size, 31, patch_size, patch_size), **self.kwargs)\n","        z = self.f(z, data, dictionary, batch_size, device)\n","\n","        # set up Jacobian vector product (without additional forward calls)\n","        z0 = z.clone().detach().requires_grad_()\n","        f0 = self.f(z0, data, dictionary, batch_size, device)\n","        def backward_hook(grad):\n","            g, self.backward_res = self.solver(lambda y : autograd.grad(f0, z0, y, retain_graph=True)[0] + grad,\n","                                               grad, **self.kwargs)\n","            return g\n","        z.register_hook(backward_hook)\n","        return z\n","\n","def equilibrium_model_training(my_sc_model, num_epochs, learning_rate, dataloader_train,\n","                               D, device, l2_w, sparsity_level, batch_size,\n","                               patch_size):\n","    criterion = nn.MSELoss()\n","    #criterion = nn.L1Loss()\n","    optimizer = torch.optim.Adam(my_sc_model.parameters(), lr=learning_rate, weight_decay=l2_w)\n","    for epoch in range(num_epochs):\n","       acc_loss = 0.\n","       for Ds, data, clean in dataloader_train:\n","\n","           batch_size = len(data)\n","           data = (data.float()).to(device)\n","           Ds = (Ds.float()).to(device)\n","           clean = (clean.float()).to(device)\n","           clean = torch.reshape(clean, (batch_size, Ds.shape[1], patch_size, patch_size))\n","           # ===================forward=====================\n","           output = my_sc_model(data, Ds, batch_size, device)\n","           loss = torch.sqrt(criterion(output, clean))\n","           #loss = criterion(output, clean)\n","           # ===================backward====================\n","           optimizer.zero_grad()\n","           loss.backward()\n","           optimizer.step()\n","           acc_loss += loss.item()\n","       #if epoch%10 == 0:\n","         #torch.save(my_sc_model,\"/content/drive/MyDrive/Colab Notebooks/DEEP_UNROLLING_phd/models/fast_eq_50_50x50.pt\")\n","\n","       print(acc_loss / len(dataloader_train))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"UIgZ-vygGTTr"},"outputs":[],"source":["#@title Pretraining DnCNN\n","class DnCnn_net(nn.Module):\n","       def __init__(self, num_of_layers, features, input_channels):\n","         super().__init__()\n","         kernel_size = 3\n","         padding = 1\n","         features = features\n","         channels = input_channels\n","         num_of_layers = num_of_layers\n","         layers = []\n","         layers.append(nn.utils.spectral_norm(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False)))\n","         layers.append(nn.ReLU(inplace=True))\n","         for _ in range(num_of_layers-2):\n","             layers.append(nn.utils.spectral_norm(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False)))\n","             #layers.append(nn.BatchNorm2d(features))\n","             layers.append(nn.ReLU())\n","         layers.append(nn.utils.spectral_norm(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False)))\n","         self.dncnn = (nn.Sequential(*layers))\n","\n","       def forward(self, input):\n","           return self.dncnn(input)\n","\n","def pretraining(DnCnn_model, num_epochs, learning_rate, dataloader_pretrain, D, device, l2_w,\n","                 sparsity_level, batch_size, patch_size):\n","     criterion = nn.MSELoss()\n","     #criterion = nn.L1Loss()\n","     optimizer = torch.optim.Adam(DnCnn_model.parameters(), lr=learning_rate, weight_decay=l2_w)\n","\n","     for epoch in range(num_epochs):\n","        acc_loss = 0.\n","        for s, data_noisy, clean in dataloader_pretrain:\n","            # if batch_size>1:\n","            batch_size = len(data_noisy)\n","            data_noisy = (data_noisy.float()).to(device)\n","            data_noisy = torch.reshape(data_noisy, (batch_size, clean.shape[1], patch_size, patch_size))\n","            clean = (clean.float()).to(device)\n","            clean = torch.reshape(clean, (batch_size, clean.shape[1], patch_size, patch_size))\n","            # ===================forward=====================\n","            output = DnCnn_model(data_noisy)\n","            loss = torch.sqrt(criterion(output, clean))\n","            #loss = (criterion(output, clean))\n","            # ===================backward====================\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            acc_loss += loss.item()\n","        print(acc_loss / len(dataloader_pretrain))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eja4vQiQGh0x"},"outputs":[],"source":["#@title Training Phase\n","#Read the dictionary\n","matData = scipy.io.loadmat(\"/content/drive/MyDrive/DATA_ICVL/dictionary_test_1.mat\")\n","D = matData['D']\n","\n","# X = scipy.io.loadmat(\"/content/drive/MyDrive/DATA_ICVL/Indian_pines.mat\")\n","# X = X['indian_pines']\n","#Parameters\n","image_path = \"/content/drive/MyDrive/DATA_ICVL/Train_colored\"\n","num_of_patches = 9\n","patch_size = 50\n","sparsity_level = 12\n","noIm_start = 0\n","noIm_end = 50\n","sigma = 2\n","gaus_sigma = 0.000005\n","rcond = 1e-05\n","\n","# create the training dataset\n","train_Support, train_Data, train_clean = construct_the_training_dataset(\n","    num_of_patches, patch_size, sparsity_level, D, image_path, noIm_start, noIm_end, sigma, gaus_sigma, rcond)\n","\n","train_Support = np.float32(train_Support)\n","train_Data = np.float32(train_Data)\n","train_clean = np.float32(train_clean)\n","\n","# Create the dataloader\n","batch_size = 6\n","train_ds = TensorDataset(torch.from_numpy(train_Support), torch.from_numpy(train_Data), torch.from_numpy(train_clean))\n","dataloader_train = DataLoader(train_ds, batch_size, shuffle=False)\n","del train_ds\n","del train_Support, train_Data, train_clean\n","\n","#Pretrain the DnCnn model\n","l2_w = 1e-08\n","num_epochs = 50\n","learning_rate = 1e-3\n","\n","#Denoiser and pretraining\n","DnCnn_model = DnCnn_net(5, 64, 31).to(device)\n","# DnCnn_model = MemNet(31, 64, 5, 3).to(device )\n","# pretraining(DnCnn_model, num_epochs, learning_rate, dataloader_train, D, device, l2_w, sparsity_level,\n","#                                batch_size, patch_size)\n","# learning_rate = 1e-4\n","# pretraining(DnCnn_model, num_epochs, learning_rate, dataloader_train, D, device, l2_w, sparsity_level,\n","#                                batch_size, patch_size)\n","\n","#DeQ Model\n","l2_w = 1e-08\n","num_epochs = 50\n","learning_rate = 1e-4\n","patch_size = 50\n","init_value = 10.99\n","eq_module = HQS_Module(sparsity_level, patch_size, init_value, DnCnn_model).to(device)\n","my_sc_model = DEQFixedPoint(eq_module, sparsity_level, patch_size, device, anderson, m=5, lam=1e-03, max_iter=25, tol=1e-3, beta=1.0).to(device)\n","\n","learning_rate = 1e-4\n","num_epochs = 80\n","equilibrium_model_training(my_sc_model, num_epochs, learning_rate, dataloader_train,\n","                           D, device, l2_w, sparsity_level, batch_size,\n","                           patch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33899,"status":"ok","timestamp":1673906836022,"user":{"displayName":"Alexandros Gkillas","userId":"06090391217186072891"},"user_tz":-120},"id":"-awl_G3zGreF","outputId":"4cd22598-beba-4ff8-b6ad-536d2acd0fc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","bgu_0403-1525.mat\n","1\n","eve_0331-1549.mat\n","2\n","bulb_0822-0909.mat\n","3\n","BGU_0522-1211.mat\n","4\n","BGU_0522-1201.mat\n","5\n","bgu_0403-1511.mat\n","6\n","bgu_0403-1444.mat\n","7\n","BGU_0403-1419-1.mat\n","8\n","bguCAMP_0514-1724.mat\n","9\n","bguCAMP_0514-1723.mat\n","10\n","bguCAMP_0514-1718.mat\n","11\n","bguCAMP_0514-1659.mat\n","12\n","eve_0331-1606.mat\n","13\n","eve_0331-1633.mat\n","14\n","eve_0331-1646.mat\n","15\n","eve_0331-1647.mat\n","16\n","gavyam_0823-0930.mat\n","17\n","hill_0325-1235.mat\n","18\n","hill_0325-1228.mat\n","19\n","gavyam_0823-0944.mat\n","20\n","gavyam_0823-0933.mat\n","21\n","Lehavim_0910-1630.mat\n","22\n","Lehavim_0910-1626.mat\n","23\n","lehavim_0910-1610.mat\n","24\n","lehavim_0910-1607.mat\n","25\n","nachal_0823-1145.mat\n","26\n","nachal_0823-1144.mat\n","27\n","nachal_0823-1047.mat\n","28\n","nachal_0823-1038.mat\n","29\n","nachal_0823-1147.mat\n","30\n","omer_0331-1131.mat\n","31\n","omer_0331-1104.mat\n","32\n","objects_0924-1602.mat\n","33\n","objects_0924-1557.mat\n","34\n","objects_0924-1556.mat\n","35\n","objects_0924-1550.mat\n","36\n","nachal_0823-1222.mat\n","37\n","peppers_0503-1315.mat\n","38\n","rsh_0406-1413.mat\n","39\n","prk_0328-1031.mat\n","40\n","plt_0411-1155.mat\n","41\n","pepper_0503-1236.mat\n","38.99499162073993\n","0.9505339320805037\n","0.06187918577224122\n","5.986213006452284\n"]}],"source":["#@title Testing Phase\n","#--------------------------------------------------------------------------------------------------------------#\n","\n","sigma = 50\n","patch_size = 100\n","#Testing\n","image_test_path = \"/content/drive/MyDrive/DATA_ICVL/Test\"\n","psnr_n1 = []\n","sim_n = []\n","sam_n = []\n","time_rec = []\n","\n","# my_sc_model=torch.load(\"/content/drive/MyDrive/Colab Notebooks/DEEP_UNROLLING_phd/models/fast_eq_30_50x50.pt\")\n","\n","for kk in range (42):\n","    print(kk)\n","    #Test reconstruction\n","    X = read_test_hyperspectral_images(image_test_path, kk)\n","    X_noisy = add_gaussian_noise_matrix_form(X, sigma)\n","\n","    # X_noisy = add_gaussian_noise_matrix_form_colored(X, sigma)\n","    # X_noisy = add_gaussian_noise_matrix_form_colored_stripe(X, sigma)\n","\n","    # X_noisy = add_gaussian_noise_matrix_form_colored_deadline(X, sigma)\n","\n","\n","    # X_noisy = scipy.ndimage.gaussian_filter(X_noisy, 0.005)\n","\n","    tic()\n","    X_recon = reconstruct_hyperspectral_image(X, X_noisy, patch_size, sparsity_level,\n","                                              D, my_sc_model, rcond, device, 5)\n","    time_rec.append((toc()))\n","\n","    X_recon[X_recon>1]=1\n","    X_recon[X_recon<0]=0\n","\n","    a, b, c = MSIQA(torch.from_numpy(X*255), torch.from_numpy(X_recon*255))\n","\n","    psnr_n1.append(a)\n","    sim_n.append(b)\n","    sam_n.append(c)\n","\n","print(np.mean(psnr_n1))\n","print(np.mean(sim_n))\n","print(np.mean(sam_n))\n","print(np.mean(time_rec))\n","\n","# kk=10\n","# fig = plt.figure(figsize=(15,10))\n","# plt.imshow(np.uint8(X_recon[:,:,23]*255), cmap='gray', aspect='auto')\n","# fig = plt.figure(figsize=(15,10))\n","# plt.imshow(np.uint8(X_noisy[:,:,23]*255), cmap='gray', aspect='auto')\n","# fig = plt.figure(figsize=(15,10))\n","# plt.imshow(np.uint8(X[:,:,23]*255), cmap='gray', aspect='auto')\n","\n","# [50:1050-50, 50:1050-50, :]\n","# [50:1050-50, 50:1050-50, :]\n","a, b, c = MSIQA(torch.from_numpy(X*255), torch.from_numpy(X_noisy*255))\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}